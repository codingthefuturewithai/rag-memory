# RAG Memory Test Configuration
#
# Used by automated tests (pytest)
# Safe to commit - no real secrets, uses test database containers
#
# Database URLs point to test Docker Compose services
# Mounts point to test-data/ for test document ingestion

server:
  # Test database (port 54323 from docker-compose.test.yml)
  database_url: postgresql://raguser:ragpassword@localhost:54323/rag_memory_test

  # Test Neo4j (port 7689 from docker-compose.test.yml)
  neo4j_uri: bolt://localhost:7689
  neo4j_http_port: 7476
  neo4j_user: neo4j
  neo4j_password: test-password

  # OPENAI_API_KEY comes from .env (loaded by conftest.py)

  # Graphiti LLM Models (override defaults to use standard GPT models)
  # These avoid the o1 reasoning models which require special parameters
  graphiti_model: gpt-4o           # Main extraction model (complex entity/relationship extraction)
  graphiti_small_model: gpt-4o-mini  # Small task model (simple classifications)

mounts:
  # Test documents for automated file/directory ingestion tests
  # Using relative path - will resolve relative to project root where MCP server runs
  - path: /Users/timkitchens/projects/ai-projects/rag-memory
    read_only: true
